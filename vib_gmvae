import os
import numpy as np
import pandas as pd
import plotly.graph_objects as go
import torch
from torch import nn, optim
from torch.distributions import Normal, Categorical
from sklearn.preprocessing import StandardScaler
from sklearn.mixture import GaussianMixture
from tqdm import tqdm

#####################################
# GPU DEVICE CONFIGURATION
#####################################
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#####################################
# VIB MODEL DEFINITION
#####################################
class VIB(nn.Module):
    def __init__(self, input_dim, latent_dim=10):
        super(VIB, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 64),
            nn.ReLU()
        )
        self.mean_fc = nn.Linear(64, latent_dim)
        self.logvar_fc = nn.Linear(64, latent_dim)

    def forward(self, x):
        hidden = self.encoder(x)
        mean = self.mean_fc(hidden)
        logvar = self.logvar_fc(hidden)
        std = torch.exp(0.5 * logvar)
        z = mean + std * torch.randn_like(std)  # Reparameterization trick
        return z, mean, std

    def loss_function(self, mean, logvar):
        return -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())

#####################################
# GMVAE MODEL DEFINITION
#####################################
class GMVAE(nn.Module):
    def __init__(self, latent_dim=10, num_components=10):
        super(GMVAE, self).__init__()
        self.latent_dim = latent_dim
        self.num_components = num_components

        self.gmm = GaussianMixture(n_components=num_components, covariance_type='full')

    def fit_gmm(self, Z):
        """ Fit GMM on the extracted latent representations. """
        self.gmm.fit(Z)

    def predict(self, Z):
        """ Predict clusters using GMM. """
        return self.gmm.predict(Z)

#####################################
# TRAINING FUNCTIONS
#####################################
def train_vib(X, epochs=50, lr=1e-3):
    model = VIB(input_dim=X.shape[1]).to(device)
    optimizer = optim.Adam(model.parameters(), lr=lr)
    
    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)

    for epoch in tqdm(range(epochs), desc="Training VIB on GPU"):
        optimizer.zero_grad()
        Z, mean, logvar = model(X_tensor)
        loss = model.loss_function(mean, logvar)
        loss.backward()
        optimizer.step()

    return model

def train_gmvae(Z):
    model = GMVAE(latent_dim=Z.shape[1])
    model.fit_gmm(Z)
    return model

#####################################
# PROCESS FUNCTION FOR G & GS
#####################################
def process_class(dfRadar, class_label):
    """
    Process class G or GS using VIB + GMVAE.
    """
    df_class = dfRadar[dfRadar["labels"] == class_label].copy()

    # Feature extraction
    feature_cols = [
        "Range", "Azimuth", "VrelRad", "SNR", "RCS",
        "aa", "bb", "cc", "dd", "ee", "ff", "gg",
        "RangeVar", "Azimuth var", "VrelRad var", "Elev Var",
        "hh", "jj", "kk", "Elevation Angle", "beamforming model type"
    ]
    X = df_class[feature_cols].values
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Train VIB model
    vib_model = train_vib(X_scaled)
    
    # Extract latent representations
    with torch.no_grad():
        X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(device)
        Z, _, _ = vib_model(X_tensor)
    Z_np = Z.cpu().numpy()

    # Train GMVAE model
    gmvae_model = train_gmvae(Z_np)
    
    # Predict clusters
    cluster_preds = gmvae_model.predict(Z_np)

    # Assign labels
    cluster_labels = [f"{class_label}{i+1}" for i in cluster_preds]
    df_class.loc[:, "labels"] = cluster_labels

    return df_class

#####################################
# PLOTTING FUNCTION
#####################################
def plot_detections(dfRadar, dfGND, output_html):
    """
    Create a scatter plot of detections colored by class and save as an HTML file.
    """
    # Count detections for legend
    counts = dfRadar["labels"].value_counts().to_dict()

    # Define color mapping
    unique_labels = dfRadar["labels"].unique()
    color_palette = [
        "red", "cyan", "orange", "grey", "blue", "green", "purple", "brown", 
        "pink", "lime", "teal", "navy", "magenta", "yellow", "olive", "violet"
    ]
    color_map = {label: color_palette[i % len(color_palette)] for i, label in enumerate(unique_labels)}

    data = []

    # Add radar detections
    for label, color in color_map.items():
        subset = dfRadar[dfRadar["labels"] == label]
        data.append(go.Scatter(
            x=subset["Azimuth"], y=subset["Range"],
            mode='markers', marker=dict(size=2, color=color),
            name=f"{label} ({counts.get(label, 0)})"
        ))

    # Add ground truth trajectory
    data.append(go.Scatter(
        x=dfGND["Azimuth"], y=dfGND["Range"],
        mode='markers+lines',
        marker=dict(size=2, color="magenta"),
        line=dict(width=1, color="magenta"),
        name="Ground Truth"
    ))

    # Create figure
    fig = go.Figure(data=data)
    fig.update_layout(title="Radar Artifact Classification",
                      xaxis_title="Azimuth",
                      yaxis_title="Range",
                      showlegend=True)
    fig.write_html(output_html)
    print(f"Plot saved: {output_html}")

#####################################
# MAIN FUNCTION TO PROCESS MULTIPLE TESTCASES
#####################################
def process_testcases(root_folder):
    """
    Process all test cases in the root folder.
    """
    testcases = [d for d in os.listdir(root_folder) if os.path.isdir(os.path.join(root_folder, d))]

    for testcase in testcases:
        print(f"Processing {testcase}...")
        ftr_dir = os.path.join(root_folder, testcase, "ftr")

        # Load data
        dfRadar = pd.read_feather(os.path.join(ftr_dir, "radar.ftr"))
        dfGND = pd.read_feather(os.path.join(ftr_dir, "gnd.ftr"))

        # Process "G" and "GS" separately
        df_G = process_class(dfRadar, "G")
        df_GS = process_class(dfRadar, "GS")

        # Merge labeled data back into radar dataframe
        dfRadar.update(df_G)
        dfRadar.update(df_GS)

        # Save updated dataframe
        dfRadar.to_feather(os.path.join(ftr_dir, "radar_labeled.ftr"))

        # Generate plot
        plot_detections(dfRadar, dfGND, os.path.join(ftr_dir, "detections_plot.html"))

# Run process on all testcases in a given root folder
process_testcases("./testcases_root")
